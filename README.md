GESTURE VOLUME CONTROL PROJECT

INTRODUCTION:

Gesture recognition helps computers to understand human body language. This helps to build a more potent link between humans and machines, 
rather than just the basic text user interfaces or graphical user interfaces 
In this project for gesture recognition, the human bodyâ€™s motions are read by computer camera. 
Thecomputer then makes use of this data as input to handle applications. 
The objective of this project is to develop an interface which will capture human hand gesture dynamically and will control the volume level.

![image](https://github.com/Priyavarthini08/GestureVolumeControl-CVproject/assets/145207599/642e5130-7c6a-4141-9b48-56b8f6cfa979)

REQUIRED MODULES:

opencv-python -to perform operations associated with computer vision
mediapipe -open-source machine learning library of Google, which has some solutions for hand detection and gesture recognition
Pycaw - Python Audio Control Library
comtypes -Python COM package
numpy -library for the Python programming language, adding support for large, multi-dimensional arrays and matrices


WORKING PRINCIPLE:

The camera in our device is used for this project. 
It detects our hand with points in it so as it can see the distance between our thumb finger tip and index finger tip.
The distance between the points 4 and 8 is directly proportional to the volume of device.

APPLICATION:

Gesture based volume control can be applied in many fields like 
enabling healthcare professionals to adjust volume of medical imaging systems, control volume of different audio tracks, can be integrated in gaming and smart tv
